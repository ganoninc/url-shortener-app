receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317

      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
  tail_sampling:
    decision_wait: 15s
    num_traces: 2000
    expected_new_traces_per_sec: 50
    policies:
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]

      - name: slow-requests
        type: latency
        latency:
          threshold_ms: 100
          # todo change value

      - name: baseline
        type: probabilistic
        probabilistic:
          sampling_percentage: 5

exporters:
  otlp/jaeger:
    endpoint: "jaeger:4317"
    tls:
      insecure: true

  prometheus:
    endpoint: 0.0.0.0:8888

  # debug:
  #   verbosity: normal

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors:
        - batch
        - tail_sampling
      exporters:
        - otlp/jaeger
        # - debug

    # logs:
    #   receivers: [otlp]
    #   processors: [batch]
    # exporters:
    # - debug

  telemetry:
    metrics:
      readers:
        - pull:
            exporter:
              prometheus:
                host: "0.0.0.0"
                port: 8888
